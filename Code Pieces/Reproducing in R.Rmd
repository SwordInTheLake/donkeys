---
title: "Reproducing in R"
author: "Team"
date: "5/14/2020"
output: html_document
---

```{r}
library(dplyr)
library(ggplot2)
library(olsrr)
library(lmtest)
library(numbers)
library(paranomo)
```

```{r}
# Read in donkeys
donkeys <- data.frame(donkeys)

# drop BCS = 4.5 and BCS = 1
donkeys <- subset(donkeys, BCS!=4.5 & BCS!=1)

# drop baby donkey 
donkeys <- subset(donkeys, Weight != 27)
donkeys <- donkeys[order(donkeys$Weight),]

# train-test split
train <- NULL
test <- NULL 
for(i in 1:nrow(donkeys)){
  if (mod(i,5) == 0){
    test <- rbind(test, donkeys[i,])
  }
  else{
    train <- rbind(train, donkeys[i,])
  }
}

train$BCS <- as.factor(train$BCS)
train$Age <- as.factor(train$Age)
train$Sex <- as.factor(train$Sex)
#train$Legs <- train$Height - train$Girth/pi

test$BCS <- as.factor(test$BCS)
test$Age <- as.factor(test$Age)
test$Sex <- as.factor(test$Sex)

# dropping some values to match their training set
train_reproducing <- subset(train, BCS==3.0)
train_reproducing <- subset(train_reproducing, Age!='<2')
train_reproducing <- subset(train_reproducing, Age!='2-5')

# The following are the csvs on our github (from Notebook)- they give different results than the code above 
#train_dan = data.frame(read.table("train.csv", sep=",", header=TRUE))
#test_dan = data.frame(read.table("test.csv", sep=",", header=TRUE))
#train_reproducing = data.frame(read.table("train_reproducing.csv", sep=",", header = TRUE))
```

```{r}
model.rep = lm(2*(sqrt(Weight)-1) ~ log(Length) + log(Girth), data=train_reproducing)
summary(model.rep)
```

* Note that the values obtained are significantly different
* b0_given = -107
* b1_given = 19.91
* b2_given = 7.712

```{r}
f = -107 + 19.91*log(test$Girth)
g = 7.712*log(test$Length)
raw_weight = (((f+g)/2) + 1)^2
```

```{r}
levels(test$Age)
levels(test$BCS)
```

```{r}
age_adjustment <- function(num){
  list = c(-8,-4,0,0,0,0)
  return(list[num])
}
bcs_adjustment <- function(num){
  list = c(NA,-10,-6,-5,0,6,14,NA)
  return(list[num])
}
age = sapply(as.numeric(test$Age),age_adjustment)
bcs = sapply(as.numeric(test$BCS),bcs_adjustment)
author_predicted = raw_weight + age + bcs
```

```{r}
actual_over_predicted = test$Weight/author_predicted
n = length(actual_over_predicted)
h <- hist(actual_over_predicted, breaks = 4, main = "Distribution of relative errors, actual/predicted")
text(h$mids,h$counts,labels=paste(signif(100*h$counts/n,3),"%"), adj=c(0.5, -0.5))
```

```{r}
ggplot(test, aes(x = author_predicted, y = Weight)) + geom_point(color = "red") + xlim(75,225) + ylim(75,225) + geom_abline(intercept = 0, slope = 1, size=0.9) + 
geom_abline(intercept = 0, slope = 1.1, color="gray", linetype = "dashed", size=1) + 
geom_abline(intercept = 0, slope = .9, color="gray", linetype = "dashed", size=1) + 
geom_abline(intercept = 0, slope = .8, color="gray", linetype = "dotted", size=1) + 
geom_abline(intercept = 0, slope = 1.2, color="gray", linetype = "dotted", size=1) + 
scale_x_continuous(name = "Predicted", breaks = seq(75,225,25), limits = c(75,225)) + 
scale_y_continuous(name = "Actual Weights", breaks = seq(75,225,25), limits = c(75,225))
```


# Get quantitative results

* We believe predicted/actual to be more statistically correct. 

```{r}
plot_histogram <- function(list, title, subdivide){
  if (subdivide){
    h <- hist(list, main=title, breaks = 16)
  }
  else{
    h <- hist(list, main=title)
  }
  text(h$mids,h$counts,labels=h$counts, adj=c(0.5, -0.5))
}
```

```{r}
results <- function(predicted, actual, breaks){
  residuals = predicted - actual
  relative_error = predicted/actual
  MSE = mean(residuals^2)
  cat("The MSE is", MSE,'\n')
  cat("The relative error is",mean((relative_error-1)^2))
  plot_histogram(residuals, "Histogram of Residuals", breaks)
  plot_histogram(relative_error, "Histogram of Relative Error", FALSE)
}
```

```{r}
results(author_predicted,test$Weight,TRUE)
```


